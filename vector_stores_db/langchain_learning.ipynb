{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342ba88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c482c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = OpenAI(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91841dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI think autoencoders are a useful and powerful tool in the field of deep learning. They allow for unsupervised learning and can be used for tasks such as data compression, feature extraction, and anomaly detection. They can also be combined with other neural network architectures to improve performance on supervised learning tasks. However, they can be difficult to train and require a lot of data to perform well. Overall, I believe autoencoders have a lot of potential and are an important component of modern machine learning systems.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what do you think about autoencoders?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## completion models\n",
    "# Use /v1/completions endpoint\n",
    "# Examples:\n",
    "\n",
    "# davinci-003\n",
    "\n",
    "# text-davinci-003\n",
    "\n",
    "# gpt-3.5-turbo-instruct\n",
    "\n",
    "# gpt-4o-mini-tts (specialized)\n",
    "\n",
    "# These work with plain prompt= strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caebe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chat completion models\n",
    "\n",
    "# Use /v1/chat/completions endpoint\n",
    "# Examples:\n",
    "\n",
    "# gpt-4o-mini\n",
    "\n",
    "# gpt-4o\n",
    "\n",
    "# gpt-3.5-turbo-0125\n",
    "\n",
    "# gpt-4.1-mini\n",
    "\n",
    "# Claude models (Anthropic)\n",
    "\n",
    "# Most new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a6fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completion models can do ANY text generation task:\n",
    "\n",
    "# Q&A\n",
    "\n",
    "# summarization\n",
    "\n",
    "# translation\n",
    "\n",
    "# code generation\n",
    "\n",
    "# classification\n",
    "\n",
    "# creative writing\n",
    "\n",
    "# few-shot prompting\n",
    "\n",
    "# role-playing\n",
    "\n",
    "# chain-of-thought (though less reliable)\n",
    "\n",
    "# structured extraction\n",
    "\n",
    "# They just don’t have roles (system, user, assistant) and don’t understand multi-turn dialogs natively.b\n",
    "\n",
    "# The prompt must contain EVERYTHING:\n",
    "\n",
    "# instructions\n",
    "\n",
    "# persona\n",
    "\n",
    "# boundaries\n",
    "\n",
    "# examples\n",
    "\n",
    "# user input\n",
    "\n",
    "# expected output format\n",
    "\n",
    "# All in one long string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2bf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool/function calling\n",
    "\n",
    "# multi-turn memory\n",
    "\n",
    "# role-based conditioning\n",
    "\n",
    "# safer guardrails\n",
    "\n",
    "# less prompt injection\n",
    "\n",
    "# better instruction following\n",
    "\n",
    "# RAG pipelines easily\n",
    "\n",
    "# flexible conversational flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05921663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64316285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Ingestion (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
