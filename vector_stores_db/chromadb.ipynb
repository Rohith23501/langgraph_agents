{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff9fc91",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "\n",
    "#### Introduction \n",
    "RAG is a technique with which we increase the answering capabilities of LLM by giving them \n",
    "relevant, updated context from external source utilizing the language and knowledge acquired by the LLMS through training\n",
    "\n",
    "* LangChain : A framework which is useful in developing applications powered by language models\n",
    "* ChromaDB : A vector database which we can use to store and search for vector embeddings to get the relevant context\n",
    "* OpenAI : we can get pretrained LLM models and embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7fc8ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d15f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "## vectorstores \n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ac24624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG (Retrieval-Augmented Generation) Architecture:\n",
      "\n",
      "1. Document Loading: Load documents from various sources\n",
      "2. Document Splitting: Break documents into smaller chunks\n",
      "3. Embedding Generation: Convert chunks into vector representations\n",
      "4. Vector Storage: Store embeddings in ChromaDB\n",
      "5. Query Processing: Convert user query to embedding\n",
      "6. Similarity Search: Find relevant chunks from vector store\n",
      "7. Context Augmentation: Combine retrieved chunks with query\n",
      "8. Response Generation: LLM generates answer using context\n",
      "\n",
      "Benefits of RAG:\n",
      "- Reduces hallucinations\n",
      "- Provides up-to-date information\n",
      "- Allows citing sources\n",
      "- Works with domain-specific knowledge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56440cf0",
   "metadata": {},
   "source": [
    "#### 1.Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "38104234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "58f38352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: C:\\Users\\rohit\\AppData\\Local\\Temp\\tmpxjwsaa9p\n",
      "doc_1.txt doc_2.txt doc_3.txt\n"
     ]
    }
   ],
   "source": [
    "## save files temporarily\n",
    "import tempfile \n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, content in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i+1}.txt\", 'w') as empty_file:\n",
    "        empty_file.write(content)\n",
    "\n",
    "print(f\"Directory: {temp_dir}\")\n",
    "print(*list(os.listdir(temp_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb39637",
   "metadata": {},
   "source": [
    "#### 2. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1f4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = \"C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4da10153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loaded Documents: 3\n",
      "======\n",
      "\n",
      " First document preview: \n",
      " \n",
      "    Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
      "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties.\n",
      "    \n",
      "Metadata: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "## load all the text files from the directory \n",
    "loader = DirectoryLoader(\n",
    "    temp_dir, \n",
    "    glob = ['**/doc_*.txt'], \n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs = {'encoding': 'utf-8'}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Total Loaded Documents: {len(documents)}\")\n",
    "print(f\"======\")\n",
    "print(f\"\\n First document preview: \\n {documents[0].page_content}\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a7d414a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mrepr\u001b[39m(\u001b[43msample_docs\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_docs' is not defined"
     ]
    }
   ],
   "source": [
    "repr(sample_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e22c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b83a855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 chunks from 3 documents\n",
      "=============\n",
      "\n",
      "Chunk exmaple:\n",
      "Content: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experie...\n",
      "Metadata: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}\n"
     ]
    }
   ],
   "source": [
    "### Document Splitting \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, # would like to experiment by lowering this\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\" \"] \n",
    "\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"=============\")\n",
    "print(f\"\\nChunk exmaple:\")\n",
    "print(f\"Content: {chunks[0].page_content[: 150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf025e",
   "metadata": {},
   "source": [
    "#### Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7586287",
   "metadata": {},
   "source": [
    "#### Initializing ChromaDB Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9e3d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75726075",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb_directory = \"./chroma.db\"\n",
    "\n",
    "## Initialize Chromadb  with OpenAI embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=vdb_directory,\n",
    "    collection_name=\"rag_vdb_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53ac5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aadd_documents\n",
      "aadd_texts\n",
      "add_documents\n",
      "add_images\n",
      "add_texts\n",
      "adelete\n",
      "afrom_documents\n",
      "afrom_texts\n",
      "aget_by_ids\n",
      "amax_marginal_relevance_search\n",
      "amax_marginal_relevance_search_by_vector\n",
      "as_retriever\n",
      "asearch\n",
      "asimilarity_search\n",
      "asimilarity_search_by_vector\n",
      "asimilarity_search_with_relevance_scores\n",
      "asimilarity_search_with_score\n",
      "delete\n",
      "delete_collection\n",
      "embeddings\n",
      "encode_image\n",
      "from_documents\n",
      "from_texts\n",
      "get\n",
      "get_by_ids\n",
      "max_marginal_relevance_search\n",
      "max_marginal_relevance_search_by_vector\n",
      "override_relevance_score_fn\n",
      "persist\n",
      "search\n",
      "similarity_search\n",
      "similarity_search_by_image\n",
      "similarity_search_by_image_with_relevance_score\n",
      "similarity_search_by_vector\n",
      "similarity_search_by_vector_with_relevance_scores\n",
      "similarity_search_with_relevance_scores\n",
      "similarity_search_with_score\n",
      "update_document\n",
      "update_documents\n"
     ]
    }
   ],
   "source": [
    "for att_or_met in dir(vectorstore):\n",
    "    if not att_or_met.startswith(\"_\"):\n",
    "        print(att_or_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28363f4e",
   "metadata": {},
   "source": [
    "#### Text-Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a64b52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the types of machine learning ?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query, k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72306d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_search(query, vector_store=vectorstore, top_k=3):\n",
    "    return vector_store.similarity_search(query, k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fef0d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_3.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_3.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_search(\"what is NLP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77ca5cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_search(\"What is Deep Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "629f613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query_results(query, vector_store=vectorstore, top_k=3):\n",
    "    print(f\"for query: {query}\")\n",
    "    print(f\"----------------------\")\n",
    "    print(f\"The {top_k} similar results are: \")\n",
    "    print(f\"---------\")\n",
    "    for matching in query_search(query, vector_store=vector_store, top_k=top_k):\n",
    "        print(f\"Source: {matching.metadata}\")\n",
    "        print(f\"Content: {matching.page_content}\")\n",
    "        print(f\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7406b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for query: What is machine Learning\n",
      "----------------------\n",
      "The 1 similar results are: \n",
      "---------\n",
      "Source: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}\n",
      "Content: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
      "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_query_results(\"What is machine Learning\", top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2f92d",
   "metadata": {},
   "source": [
    "#### Initialize LLM, RAG Chain, Prompt Template, Query RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "626eeb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9a1b7fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM stands for Language Model for Large-scale semi-structured data. This is a deep learning model developed for processing and understanding large amounts of unstructured or semi-structured data, such as text and speech. It uses artificial intelligence techniques to analyze, interpret, and derive insights from this data, enabling applications such as natural language processing, machine translation, sentiment analysis, and more.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 14, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cctn9KrWMqmRilpAqX5TzWnyi0HST', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--519c66eb-e77f-474f-a91e-60d6c176c4e9-0', usage_metadata={'input_tokens': 14, 'output_tokens': 76, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response = llm.invoke(\"what is LLM in AI?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "031e2f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM stands for Language Model for Large-scale semi-structured data. This is a deep learning model developed for processing and understanding large amounts of unstructured or semi-structured data, such as text and speech. It uses artificial intelligence techniques to analyze, interpret, and derive insights from this data, enabling applications such as natural language processing, machine translation, sentiment analysis, and more.'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dcb49627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM stands for Language Model for Large-scale semi-structured data. This is a deep learning model developed for processing and understanding large amounts of unstructured or semi-structured data, such as text and speech. It uses artificial intelligence techniques to analyze, interpret, and derive insights from this data, enabling applications such as natural language processing, machine translation, sentiment analysis, and more.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 14, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cctn9KrWMqmRilpAqX5TzWnyi0HST', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--519c66eb-e77f-474f-a91e-60d6c176c4e9-0', usage_metadata={'input_tokens': 14, 'output_tokens': 76, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c2704c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b67aa048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of September 2021, the President of the United States is Joseph R. Biden Jr.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 14, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CctnFC1kuIfb4kYJJQerNgrXj9lTy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4695dbbe-501e-426b-afff-bc8c1f9fa109-0', usage_metadata={'input_tokens': 14, 'output_tokens': 20, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who is the president of America?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "070b99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2021, the president of America is Joe Biden.\n",
      "As of September 2021, K. Chandrashekar Rao is the Chief Minister of Telangana State, India.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Who is the president of America?\").content)\n",
    "print(llm.invoke(\"Who is the chief minister of Telanga State, India?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "31448556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are the examples which shows how we get wrong answers which were correct \n",
    "## at the training time of the data but is oudated info and incorrect currently \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46182999",
   "metadata": {},
   "source": [
    "#### Modern RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3011ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2693b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(MultiQueryRetriever())\n",
    "# will be useful when have to generate prompts \n",
    "# from query_prompt for vector search in retreiver. \n",
    "# all the necessary context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1f173811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002B9C97612B0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs= {\"k\": 3})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1d365f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_3.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "65f737a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "the context is after Content:  and the input or the question is \n",
    "after Input:\n",
    "\n",
    "Context: {context}\n",
    "Input: {Input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "50b70b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['Input', 'context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\nthe context is after Content:  and the input or the question is \\nafter Input:\\n\\nContext: {context}\\nInput: {Input}\\n\")"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template= system_prompt\n",
    "\n",
    ")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "430505ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\nthe context is after Content:  and the input or the question is \\nafter Input:\\n\\nContext: Modi is Great?\\nInput: who is great?\\n\")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({\"context\": \"Modi is Great?\", \"Input\": \"who is great?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b65efcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_docs(docs):\n",
    "    combined_content = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return combined_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8f7f3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "066ec091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives us a runnable with the same name as that of the function which is given to us by the chain decorator.\n",
    "@chain\n",
    "def get_response_with_context(qyery, vector_store=vectorstore,\n",
    "                              prompt_template=prompt_template, llm=llm, top_k=3):\n",
    "    similar_docs = vector_store.similarity_search(query, k=top_k)\n",
    "    context = join_docs(similar_docs)\n",
    "\n",
    "    prompt = prompt_template.invoke({\"context\": context, \"Input\": query})\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f945a02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nMachine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nDeep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_docs(vectorstore.similarity_search(\"What is Machine Learning?\", k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "afb358ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supervised learning, unsupervised learning, and reinforcement learning are the three main types of machine learning. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through feedback from interactions in an environment.'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_with_context.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "13817590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "13552995",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is your name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "496c9129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c759448d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is Bob. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 50, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CctnTLE9AKZtwCGuKplZxeOQjRlFA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a2c81fde-f87c-4aac-a5e6-f92dbbc82fd8-0', usage_metadata={'input_tokens': 50, 'output_tokens': 12, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8731c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f3493327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.passthrough import (RunnableAssign,\n",
    "                                                   RunnableParallel, \n",
    "                                                   RunnablePassthrough,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49f4eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query, vector_store=vectorstore, top_k=3):\n",
    "    similar_docs = vector_store.similarity_search(query, k=top_k)\n",
    "    context = join_docs(similar_docs)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3d144fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_prompt_template = RunnableParallel( \n",
    "    context = RunnableLambda(get_context),\n",
    "    Input = RunnablePassthrough()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ff952c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_pipeline = RunnableSequence(to_prompt_template, prompt_template, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "413e57bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It includes supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through interaction with an environment to achieve a goal.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 355, 'total_tokens': 423, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CctnVEMjOYH4FQgKo13727xMP4VRb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9030dd25-173a-486e-a7a3-a808f80d6eec-0', usage_metadata={'input_tokens': 355, 'output_tokens': 68, 'total_tokens': 423, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_pipeline.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbf3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = retriever | prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47b5edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\\n\\n\".join([doc.page_content for doc in retriever.invoke(\"what is machine learning?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d334124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = pipeline.invoke({\"Input\": \"how are  you?\"})\n",
    "# the above line doesn't work since the input invoke on the retriever can't deal \n",
    "# dictionary input and convert it into a query string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c60f8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_dict(query: dict, vector_store=vectorstore, top_k=3):\n",
    "    similar_docs = vector_store.similarity_search(query[\"Input\"], k=top_k)\n",
    "    context = join_docs(similar_docs)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "82e47576",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_input = RunnableAssign(\n",
    "    RunnableParallel(\n",
    "        context= RunnableLambda(get_context_dict)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ef252afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_call = template_input | prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bf4dc212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence that enables systems to learn from experience. There are three main types: supervised, unsupervised, and reinforcement learning. Supervised learning uses labeled data to train models.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 355, 'total_tokens': 397, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CctndNdCZnsWC31YDLGVhSTaaIX3L', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7135e4d4-0828-4d5c-bcab-600c79bf854b-0', usage_metadata={'input_tokens': 355, 'output_tokens': 42, 'total_tokens': 397, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_call.invoke({\"Input\": \"What is Machine Learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f6588f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = query_call.invoke({\"Input\": \"What is Deep Learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1ea3bb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning that uses artificial neural networks inspired by the human brain. It has revolutionized fields like computer vision, natural language processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly effective for image processing.'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cf44475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_answer_output = template_input | prompt_template | llm | (lambda x: x.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "de9a84c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing (NLP) is a field of AI focused on computers interacting with human language. Key tasks in NLP include text classification and sentiment analysis. NLP heavily relies on transformer architectures like BERT and GPT.'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_answer_output.invoke({\"Input\": \"What is Natural Language Processing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2d09688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_to_query = RunnableLambda(\n",
    "    lambda query: {\"Input\": query}\n",
    ").assign(docs = lambda out: retriever.invoke(out[\"Input\"])\n",
    ").assign(context = lambda out: join_docs(out[\"docs\"])\n",
    ").assign(prompt = lambda out: prompt_template.invoke({\"Input\": out[\"Input\"], \"context\": out[\"context\"]})\n",
    "         ).assign(response = lambda out: llm.invoke(out[\"prompt\"])\n",
    "         ).assign(answer = lambda out: out[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7ce0ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = answer_to_query.invoke(\"What is Reinforcement Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3a60d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning learns through interaction with an environment, using rewards and penalties for feedback. It is a type of machine learning that falls under the category of artificial intelligence. This method allows systems to learn and improve based on their experiences without explicit programming.'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ad1c5bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_on_complete__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_setattr_handlers__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_backwards_compat_tool_calls',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " '_setattr_handler',\n",
       " 'additional_kwargs',\n",
       " 'construct',\n",
       " 'content',\n",
       " 'content_blocks',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'get_lc_namespace',\n",
       " 'id',\n",
       " 'invalid_tool_calls',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'name',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pretty_print',\n",
       " 'pretty_repr',\n",
       " 'response_metadata',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'text',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'tool_calls',\n",
       " 'type',\n",
       " 'update_forward_refs',\n",
       " 'usage_metadata',\n",
       " 'validate']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(output[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8beda250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 50,\n",
       "  'prompt_tokens': 283,\n",
       "  'total_tokens': 333,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_provider': 'openai',\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'id': 'chatcmpl-CctnlH0zTtkXk6NBj2wsKOJ0hL2zU',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"response\"].response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b89be2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "eff23ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\nMachine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nDeep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "87669a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a0df9802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext: {context}\\n\\nQuestion :{question}\\n\\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"Use the following context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question :{question}\n",
    "\n",
    "Answer:\"\"\")\n",
    "\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b3030503",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the output documents for the prompt \n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"Content: {doc.page_content}\" for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d137fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a chain using LCEL \n",
    "\n",
    "rag_chain_lcel = ({\"context\": retriever | format_docs,\n",
    "                   \"question\": RunnablePassthrough()\n",
    "                  }\n",
    "                  | custom_prompt\n",
    "                  | llm\n",
    "                  | StrOutputParser()\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "50624bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning that is based on artificial neural networks. It has revolutionized fields such as computer vision, natural language processing, and speech recognition. Convolutional Neural Networks are particularly effective for image processing, while Recurrent Neural Networks and Transformers excel at sequential data processing.'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke(\"What do you think about Deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8758987f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}, page_content='Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.')]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What do you think about Deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e5bb5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_lcel(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    answer = rag_chain_lcel.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "    # Get Source documents seperately if needed \n",
    "    print(\"\\nSource Documents:\")\n",
    "    for i, doc in enumerate(retriever.invoke(question)):\n",
    "        print(f\"\\n----Source Document {i+1}:\")\n",
    "        print(f\"Content: {doc.page_content}\")\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b02a4d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Natural Language Processing?\n",
      "----------------------------------------\n",
      "Answer: Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language. Key tasks in NLP include text classification, named entity recognition, sentiment analysis, machine translation, and question answering. NLP heavily relies on transformer architectures like BERT, GPT, and T5, which use attention mechanisms to understand context and relationships between words in text.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "----Source Document 1:\n",
      "Content: Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
      "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
      "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
      "    context and relationships between words in text.\n",
      "Metadata: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_3.txt'}\n",
      "\n",
      "\n",
      "\n",
      "----Source Document 2:\n",
      "Content: Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
      "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\n",
      "Metadata: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}\n",
      "\n",
      "\n",
      "\n",
      "----Source Document 3:\n",
      "Content: Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing.\n",
      "Metadata: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_2.txt'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_rag_lcel(\"What is Natural Language Processing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "12d16dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_content = \"\"\"\n",
    "This is a newly added file for testing. \n",
    "It discusses the applications of Artificial Intelligence (AI) in various industries.\n",
    "AI has transformed sectors such as healthcare, finance, and transportation. \n",
    "Machine learning and deep learning are key components of AI that enable systems to learn from data and make predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5a6eb676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b457dcbb-040d-45e4-8cc5-c4607c5e802a']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents([Document(page_content=new_file_content, metadata={\"source\": \"new_doc.txt\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "03eed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.delete(['b457dcbb-040d-45e4-8cc5-c4607c5e802a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bc76dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make \n",
    "decisions by interacting with an environment. The agent receives rewards or penalties \n",
    "based on its actions and learns to maximize cumulative reward over time. Key concepts \n",
    "in RL include: states, actions, rewards, policies, and value functions. Popular RL \n",
    "algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \n",
    "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \n",
    "robotics, and autonomous systems.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "996a3d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.\\n'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "df2c42e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'Reinforcement Learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = Document(\n",
    "    page_content=new_document,\n",
    "    metadata= {\"source\": \"manual_addition\",\n",
    "    \"topic\": \"Reinforcement Learning\"}\n",
    ")\n",
    "\n",
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ebbb0211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'Reinforcement Learning'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'Reinforcement Learning'}, page_content='methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chunks = text_splitter.split_documents([new_doc])\n",
    "new_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fabb0546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f300f1af-410e-45a9-85d2-085eb66e753c',\n",
       " '497a198f-325f-4249-951d-2372005c9b22']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add new document to the vector store \n",
    "vectorstore.add_documents(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e0a3915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'topic': 'Reinforcement Learning', 'source': 'manual_addition'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}, page_content='data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'topic': 'Reinforcement Learning', 'source': 'manual_addition'}, page_content='methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"Advanced Reinforcement Learning\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2689a0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Chroma__query_collection',\n",
       " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_asimilarity_search_with_relevance_scores',\n",
       " '_client',\n",
       " '_client_settings',\n",
       " '_collection',\n",
       " '_cosine_relevance_score_fn',\n",
       " '_embedding_function',\n",
       " '_euclidean_relevance_score_fn',\n",
       " '_get_retriever_tags',\n",
       " '_max_inner_product_relevance_score_fn',\n",
       " '_persist_directory',\n",
       " '_select_relevance_score_fn',\n",
       " '_similarity_search_with_relevance_scores',\n",
       " 'aadd_documents',\n",
       " 'aadd_texts',\n",
       " 'add_documents',\n",
       " 'add_images',\n",
       " 'add_texts',\n",
       " 'adelete',\n",
       " 'afrom_documents',\n",
       " 'afrom_texts',\n",
       " 'aget_by_ids',\n",
       " 'amax_marginal_relevance_search',\n",
       " 'amax_marginal_relevance_search_by_vector',\n",
       " 'as_retriever',\n",
       " 'asearch',\n",
       " 'asimilarity_search',\n",
       " 'asimilarity_search_by_vector',\n",
       " 'asimilarity_search_with_relevance_scores',\n",
       " 'asimilarity_search_with_score',\n",
       " 'delete',\n",
       " 'delete_collection',\n",
       " 'embeddings',\n",
       " 'encode_image',\n",
       " 'from_documents',\n",
       " 'from_texts',\n",
       " 'get',\n",
       " 'get_by_ids',\n",
       " 'max_marginal_relevance_search',\n",
       " 'max_marginal_relevance_search_by_vector',\n",
       " 'override_relevance_score_fn',\n",
       " 'persist',\n",
       " 'search',\n",
       " 'similarity_search',\n",
       " 'similarity_search_by_image',\n",
       " 'similarity_search_by_image_with_relevance_score',\n",
       " 'similarity_search_by_vector',\n",
       " 'similarity_search_by_vector_with_relevance_scores',\n",
       " 'similarity_search_with_relevance_scores',\n",
       " 'similarity_search_with_score',\n",
       " 'update_document',\n",
       " 'update_documents']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "64d3da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7d3313c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_end():\n",
    "    import shutil\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cd6c24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the key concepts in Reinforcement Learning?\n",
      "----------------------------------------\n",
      "Answer: The key concepts in Reinforcement Learning are states, actions, rewards, policies, and value functions.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "----Source Document 1:\n",
      "Content: Reinforcement Learning in Detail\n",
      "\n",
      "Reinforcement learning (RL) is a type of machine learning where an agent learns to make \n",
      "decisions by interacting with an environment. The agent receives rewards or penalties \n",
      "based on its actions and learns to maximize cumulative reward over time. Key concepts \n",
      "in RL include: states, actions, rewards, policies, and value functions. Popular RL \n",
      "algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \n",
      "Actor-Critic methods. RL has been\n",
      "Metadata: {'source': 'manual_addition', 'topic': 'Reinforcement Learning'}\n",
      "\n",
      "\n",
      "\n",
      "----Source Document 2:\n",
      "Content: data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties.\n",
      "Metadata: {'source': 'C:\\\\Users\\\\rohit\\\\AppData\\\\Local\\\\Temp\\\\tmpxjwsaa9p\\\\doc_1.txt'}\n",
      "\n",
      "\n",
      "\n",
      "----Source Document 3:\n",
      "Content: methods, and \n",
      "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \n",
      "robotics, and autonomous systems.\n",
      "Metadata: {'topic': 'Reinforcement Learning', 'source': 'manual_addition'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_question = \"What are the key concepts in Reinforcement Learning?\"\n",
    "result = query_rag_lcel(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2c83ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "76196d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5893aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21c8ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a1c0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        You like answering questions without hallucinating.\n",
    "        You use the provided context and previous chat history to answer the question in a \n",
    "     conversational manner and keep the answers concise. \n",
    "\n",
    "     Context: {context}\n",
    "     \"\"\"), \n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{query}\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7f2231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"\\n        You like answering questions without hallucinating.\\n        You use the provided context and previous chat history to answer the question in a \\n     conversational manner and keep the answers concise. \\n\\n     Context: page_content='for now empty context'\\n     \", additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi !!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({\"history\": [HumanMessage(\"Hi !!\")], \"context\": Document(page_content=\"for now empty context\"),\n",
    "                        \"query\": \"What is Machine Learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9faf6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "182096fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def conversation_chain(query, chat_history=chat_history,\n",
    "                       vector_store=vectorstore,\n",
    "                       prompt_template=prompt_template,\n",
    "                       llm=llm, top_k=3):\n",
    "    similar_docs = vector_store.similarity_search(query, k=top_k)\n",
    "    context = join_docs(similar_docs)\n",
    "\n",
    "    prompt = prompt_template.invoke({\n",
    "        \"context\": Document(page_content=context),\n",
    "        \"history\": chat_history,\n",
    "        \"query\": query\n",
    "    })\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Update chat history\n",
    "    chat_history.append(HumanMessage(content=query))\n",
    "    chat_history.append(AIMessage(content=response.content))\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3932ede5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves training models on data to make predictions or decisions. There are three main types of machine learning: supervised, unsupervised, and reinforcement learning. Each type has its own approach to learning from data.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30912756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's the answer: \\nMachine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves training models on data to make predictions or decisions. There are three main types of machine learning: supervised, unsupervised, and reinforcement learning. Each type has its own approach to learning from data.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"can you give me your previous answer once again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ee79f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In machine learning, algorithms learn from data to make predictions or decisions without being explicitly programmed. \\n\\n1. Supervised learning involves training models on labeled data, where the algorithm learns patterns to make predictions.\\n2. Unsupervised learning finds patterns in data without predefined labels, useful for clustering or dimensionality reduction.\\n3. Reinforcement learning learns through trial and error, receiving feedback in the form of rewards or penalties to optimize decisions.\\n\\nThese approaches enable systems to improve performance over time and adapt to new data without human intervention.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"So can you get into more details for your answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a56b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatOpenAI(\n",
    "    model_name=\"gpt-4-turbo\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bcda3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three main types of machine learning are:\\n1. Supervised learning: Uses labeled data to train models and make predictions.\\n2. Unsupervised learning: Finds patterns in unlabeled data to discover hidden insights.\\n3. Reinforcement learning: Learns through trial and error by receiving feedback in the form of rewards or penalties to optimize decisions.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"So what are the types of machine learning there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12e230e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LCEL approach for conversation chain\n",
    "from langchain_core.runnables import RunnableAssign, RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d40375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'history', 'query']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dict(query): \n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def answer_content(out):\n",
    "    answer = out[\"response\"].content\n",
    "    query = out[\"query\"]\n",
    "    chat_history.append(HumanMessage(content=query))\n",
    "    chat_history.append(AIMessage(content=answer))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d12d4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lcel_try = RunnableLambda(\n",
    "    query_dict\n",
    ").assign(history = lambda out: chat_history\n",
    ").assign(context = lambda out: join_docs(vectorstore.similarity_search(out[\"query\"], k=3))\n",
    ").assign(prompt = lambda out: prompt_template.invoke({\"context\": out[\"context\"],\n",
    "                                                      \"history\": out[\"history\"],\n",
    "                                                     \"query\": out[\"query\"]})\n",
    "        ).assign(response = lambda out: llm.invoke(out[\"prompt\"])\n",
    "         ).assign(answer = answer_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80ba1340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Machine Learning?',\n",
       " 'history': [HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves training models on data to make predictions or decisions. There are three main types of machine learning: supervised, unsupervised, and reinforcement learning. Each type has its own approach to learning from data.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='can you give me your previous answer once again?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Sure! Here's the answer: \\nMachine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves training models on data to make predictions or decisions. There are three main types of machine learning: supervised, unsupervised, and reinforcement learning. Each type has its own approach to learning from data.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='So can you get into more details for your answer', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='In machine learning, algorithms learn from data to make predictions or decisions without being explicitly programmed. \\n\\n1. Supervised learning involves training models on labeled data, where the algorithm learns patterns to make predictions.\\n2. Unsupervised learning finds patterns in data without predefined labels, useful for clustering or dimensionality reduction.\\n3. Reinforcement learning learns through trial and error, receiving feedback in the form of rewards or penalties to optimize decisions.\\n\\nThese approaches enable systems to improve performance over time and adapt to new data without human intervention.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='So what are the types of machine learning there?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The three main types of machine learning are:\\n1. Supervised learning: Uses labeled data to train models and make predictions.\\n2. Unsupervised learning: Finds patterns in unlabeled data to discover hidden insights.\\n3. Reinforcement learning: Learns through trial and error by receiving feedback in the form of rewards or penalties to optimize decisions.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without needing explicit programming. It utilizes algorithms to analyze data, learn from it, and make predictions or decisions. Essentially, machine learning automates analytical model building, allowing computers to adapt to new scenarios independently. The field is divided into three main types: supervised learning, unsupervised learning, and reinforcement learning, each catering to different kinds of problems and data.', additional_kwargs={}, response_metadata={})],\n",
       " 'context': 'Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nMachine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nDeep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers',\n",
       " 'prompt': ChatPromptValue(messages=[SystemMessage(content='\\n        You like answering questions without hallucinating.\\n        You use the provided context and previous chat history to answer the question in a \\n     conversational manner and keep the answers concise. \\n\\n     Context: Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nMachine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\nDeep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n     ', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={}), AIMessage(content='Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves training models on data to make predictions or decisions. There are three main types of machine learning: supervised, unsupervised, and reinforcement learning. Each type has its own approach to learning from data.', additional_kwargs={}, response_metadata={}), HumanMessage(content='can you give me your previous answer once again?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Sure! Here's the answer: \\nMachine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves training models on data to make predictions or decisions. There are three main types of machine learning: supervised, unsupervised, and reinforcement learning. Each type has its own approach to learning from data.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='So can you get into more details for your answer', additional_kwargs={}, response_metadata={}), AIMessage(content='In machine learning, algorithms learn from data to make predictions or decisions without being explicitly programmed. \\n\\n1. Supervised learning involves training models on labeled data, where the algorithm learns patterns to make predictions.\\n2. Unsupervised learning finds patterns in data without predefined labels, useful for clustering or dimensionality reduction.\\n3. Reinforcement learning learns through trial and error, receiving feedback in the form of rewards or penalties to optimize decisions.\\n\\nThese approaches enable systems to improve performance over time and adapt to new data without human intervention.', additional_kwargs={}, response_metadata={}), HumanMessage(content='So what are the types of machine learning there?', additional_kwargs={}, response_metadata={}), AIMessage(content='The three main types of machine learning are:\\n1. Supervised learning: Uses labeled data to train models and make predictions.\\n2. Unsupervised learning: Finds patterns in unlabeled data to discover hidden insights.\\n3. Reinforcement learning: Learns through trial and error by receiving feedback in the form of rewards or penalties to optimize decisions.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={})]),\n",
       " 'response': AIMessage(content='Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without needing explicit programming. It utilizes algorithms to analyze data, learn from it, and make predictions or decisions. Essentially, machine learning automates analytical model building, allowing computers to adapt to new scenarios independently. The field is divided into three main types: supervised learning, unsupervised learning, and reinforcement learning, each catering to different kinds of problems and data.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 705, 'total_tokens': 794, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-CdDZCvaWOgyhDTjXN2FPuH8fG681W', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--288855c9-43e0-4843-92a1-4678210a6b80-0', usage_metadata={'input_tokens': 705, 'output_tokens': 89, 'total_tokens': 794, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'answer': 'Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without needing explicit programming. It utilizes algorithms to analyze data, learn from it, and make predictions or decisions. Essentially, machine learning automates analytical model building, allowing computers to adapt to new scenarios independently. The field is divided into three main types: supervised learning, unsupervised learning, and reinforcement learning, each catering to different kinds of problems and data.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lcel_try.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "470906a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "960aad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package langchain_core:\n",
      "\n",
      "NAME\n",
      "    langchain_core - `langchain-core` defines the base abstractions for the LangChain ecosystem.\n",
      "\n",
      "DESCRIPTION\n",
      "    The interfaces for core components like chat models, LLMs, vector stores, retrievers,\n",
      "    and more are defined here. The universal invocation protocol (Runnables) along with\n",
      "    a syntax for combining components (LangChain Expression Language) are also defined here.\n",
      "\n",
      "    **No third-party integrations are defined here.** The dependencies are kept purposefully\n",
      "    very lightweight.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _api (package)\n",
      "    _import_utils\n",
      "    agents\n",
      "    caches\n",
      "    callbacks (package)\n",
      "    chat_history\n",
      "    chat_loaders\n",
      "    chat_sessions\n",
      "    document_loaders (package)\n",
      "    documents (package)\n",
      "    embeddings (package)\n",
      "    env\n",
      "    example_selectors (package)\n",
      "    exceptions\n",
      "    globals\n",
      "    indexing (package)\n",
      "    language_models (package)\n",
      "    load (package)\n",
      "    messages (package)\n",
      "    output_parsers (package)\n",
      "    outputs (package)\n",
      "    prompt_values\n",
      "    prompts (package)\n",
      "    rate_limiters\n",
      "    retrievers\n",
      "    runnables (package)\n",
      "    stores\n",
      "    structured_query\n",
      "    sys_info\n",
      "    tools (package)\n",
      "    tracers (package)\n",
      "    utils (package)\n",
      "    vectorstores (package)\n",
      "    version\n",
      "\n",
      "DATA\n",
      "    VERSION = '1.0.3'\n",
      "\n",
      "VERSION\n",
      "    1.0.3\n",
      "\n",
      "FILE\n",
      "    c:\\developer\\rag_krishai_bootcamp\\data_ingestion\\.venv\\lib\\site-packages\\langchain_core\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(langchain_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b63649c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0104baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module langchain_core.chat_history in langchain_core:\n",
      "\n",
      "NAME\n",
      "    langchain_core.chat_history - **Chat message history** stores a history of the message interactions in a chat.\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        BaseChatMessageHistory\n",
      "            InMemoryChatMessageHistory(BaseChatMessageHistory, pydantic.main.BaseModel)\n",
      "\n",
      "    class BaseChatMessageHistory(abc.ABC)\n",
      "     |  Abstract base class for storing chat message history.\n",
      "     |\n",
      "     |  Implementations guidelines:\n",
      "     |\n",
      "     |  Implementations are expected to over-ride all or some of the following methods:\n",
      "     |\n",
      "     |  * add_messages: sync variant for bulk addition of messages\n",
      "     |  * aadd_messages: async variant for bulk addition of messages\n",
      "     |  * messages: sync variant for getting messages\n",
      "     |  * aget_messages: async variant for getting messages\n",
      "     |  * clear: sync variant for clearing messages\n",
      "     |  * aclear: async variant for clearing messages\n",
      "     |\n",
      "     |  add_messages contains a default implementation that calls add_message\n",
      "     |  for each message in the sequence. This is provided for backwards compatibility\n",
      "     |  with existing implementations which only had add_message.\n",
      "     |\n",
      "     |  Async variants all have default implementations that call the sync variants.\n",
      "     |  Implementers can choose to over-ride the async implementations to provide\n",
      "     |  truly async implementations.\n",
      "     |\n",
      "     |  Usage guidelines:\n",
      "     |\n",
      "     |  When used for updating history, users should favor usage of `add_messages`\n",
      "     |  over `add_message` or other variants like `add_user_message` and `add_ai_message`\n",
      "     |  to avoid unnecessary round-trips to the underlying persistence layer.\n",
      "     |\n",
      "     |  Example: Shows a default implementation.\n",
      "     |\n",
      "     |      ```python\n",
      "     |      import json\n",
      "     |      import os\n",
      "     |      from langchain_core.messages import messages_from_dict, message_to_dict\n",
      "     |\n",
      "     |\n",
      "     |      class FileChatMessageHistory(BaseChatMessageHistory):\n",
      "     |          storage_path: str\n",
      "     |          session_id: str\n",
      "     |\n",
      "     |          @property\n",
      "     |          def messages(self) -> list[BaseMessage]:\n",
      "     |              try:\n",
      "     |                  with open(\n",
      "     |                      os.path.join(self.storage_path, self.session_id),\n",
      "     |                      \"r\",\n",
      "     |                      encoding=\"utf-8\",\n",
      "     |                  ) as f:\n",
      "     |                      messages_data = json.load(f)\n",
      "     |                  return messages_from_dict(messages_data)\n",
      "     |              except FileNotFoundError:\n",
      "     |                  return []\n",
      "     |\n",
      "     |          def add_messages(self, messages: Sequence[BaseMessage]) -> None:\n",
      "     |              all_messages = list(self.messages)  # Existing messages\n",
      "     |              all_messages.extend(messages)  # Add new messages\n",
      "     |\n",
      "     |              serialized = [message_to_dict(message) for message in all_messages]\n",
      "     |              file_path = os.path.join(self.storage_path, self.session_id)\n",
      "     |              os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
      "     |              with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
      "     |                  json.dump(serialized, f)\n",
      "     |\n",
      "     |          def clear(self) -> None:\n",
      "     |              file_path = os.path.join(self.storage_path, self.session_id)\n",
      "     |              os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
      "     |              with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
      "     |                  json.dump([], f)\n",
      "     |      ```\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      BaseChatMessageHistory\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return a string representation of the chat history.\n",
      "     |\n",
      "     |  async aadd_messages(self, messages: 'Sequence[BaseMessage]') -> 'None'\n",
      "     |      Async add a list of messages.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          messages: A sequence of `BaseMessage` objects to store.\n",
      "     |\n",
      "     |  async aclear(self) -> 'None'\n",
      "     |      Async remove all messages from the store.\n",
      "     |\n",
      "     |  add_ai_message(self, message: 'AIMessage | str') -> 'None'\n",
      "     |      Convenience method for adding an `AIMessage` string to the store.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          This is a convenience method. Code should favor the bulk `add_messages`\n",
      "     |          interface instead to save on round-trips to the persistence layer.\n",
      "     |\n",
      "     |      This method may be deprecated in a future release.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          message: The `AIMessage` to add.\n",
      "     |\n",
      "     |  add_message(self, message: 'BaseMessage') -> 'None'\n",
      "     |      Add a Message object to the store.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          message: A BaseMessage object to store.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          NotImplementedError: If the sub-class has not implemented an efficient\n",
      "     |              `add_messages` method.\n",
      "     |\n",
      "     |  add_messages(self, messages: 'Sequence[BaseMessage]') -> 'None'\n",
      "     |      Add a list of messages.\n",
      "     |\n",
      "     |      Implementations should over-ride this method to handle bulk addition of messages\n",
      "     |      in an efficient manner to avoid unnecessary round-trips to the underlying store.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          messages: A sequence of `BaseMessage` objects to store.\n",
      "     |\n",
      "     |  add_user_message(self, message: 'HumanMessage | str') -> 'None'\n",
      "     |      Convenience method for adding a human message string to the store.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          This is a convenience method. Code should favor the bulk `add_messages`\n",
      "     |          interface instead to save on round-trips to the persistence layer.\n",
      "     |\n",
      "     |      This method may be deprecated in a future release.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          message: The `HumanMessage` to add to the store.\n",
      "     |\n",
      "     |  async aget_messages(self) -> 'list[BaseMessage]'\n",
      "     |      Async version of getting messages.\n",
      "     |\n",
      "     |      Can over-ride this method to provide an efficient async implementation.\n",
      "     |\n",
      "     |      In general, fetching messages may involve IO to the underlying\n",
      "     |      persistence layer.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The messages.\n",
      "     |\n",
      "     |  clear(self) -> 'None'\n",
      "     |      Remove all messages from the store.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset({'clear'})\n",
      "     |\n",
      "     |  __annotations__ = {'messages': 'list[BaseMessage]'}\n",
      "\n",
      "    class InMemoryChatMessageHistory(BaseChatMessageHistory, pydantic.main.BaseModel)\n",
      "     |  InMemoryChatMessageHistory(*, messages: list[langchain_core.messages.base.BaseMessage] = <factory>) -> None\n",
      "     |\n",
      "     |  In memory implementation of chat message history.\n",
      "     |\n",
      "     |  Stores messages in a memory list.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      InMemoryChatMessageHistory\n",
      "     |      BaseChatMessageHistory\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  async aadd_messages(self, messages: 'Sequence[BaseMessage]') -> 'None'\n",
      "     |      Async add messages to the store.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          messages: The messages to add.\n",
      "     |\n",
      "     |  async aclear(self) -> 'None'\n",
      "     |      Async clear all messages from the store.\n",
      "     |\n",
      "     |  add_message(self, message: 'BaseMessage') -> 'None'\n",
      "     |      Add a self-created message to the store.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          message: The message to add.\n",
      "     |\n",
      "     |  async aget_messages(self) -> 'list[BaseMessage]'\n",
      "     |      Async version of getting messages.\n",
      "     |\n",
      "     |      Can over-ride this method to provide an efficient async implementation.\n",
      "     |      In general, fetching messages may involve IO to the underlying\n",
      "     |      persistence layer.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List of messages.\n",
      "     |\n",
      "     |  clear(self) -> 'None'\n",
      "     |      Clear all messages from the store.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'messages': 'list[BaseMessage]'}\n",
      "     |\n",
      "     |  __class_vars__ = set()\n",
      "     |\n",
      "     |  __private_attributes__ = {}\n",
      "     |\n",
      "     |  __pydantic_complete__ = True\n",
      "     |\n",
      "     |  __pydantic_computed_fields__ = {}\n",
      "     |\n",
      "     |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.chat_history...\n",
      "     |\n",
      "     |  __pydantic_custom_init__ = False\n",
      "     |\n",
      "     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      "     |\n",
      "     |  __pydantic_fields__ = {'messages': FieldInfo(annotation=list[BaseMessa...\n",
      "     |\n",
      "     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      "     |\n",
      "     |  __pydantic_parent_namespace__ = None\n",
      "     |\n",
      "     |  __pydantic_post_init__ = None\n",
      "     |\n",
      "     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      "     |      Model...\n",
      "     |\n",
      "     |  __pydantic_setattr_handlers__ = {}\n",
      "     |\n",
      "     |  __pydantic_validator__ = SchemaValidator(title=\"InMemoryChatMessageHis...\n",
      "     |\n",
      "     |  __signature__ = <Signature (*, messages: list[langchain_core.messages....\n",
      "     |\n",
      "     |  model_config = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseChatMessageHistory:\n",
      "     |\n",
      "     |  __str__(self) -> 'str'\n",
      "     |      Return a string representation of the chat history.\n",
      "     |\n",
      "     |  add_ai_message(self, message: 'AIMessage | str') -> 'None'\n",
      "     |      Convenience method for adding an `AIMessage` string to the store.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          This is a convenience method. Code should favor the bulk `add_messages`\n",
      "     |          interface instead to save on round-trips to the persistence layer.\n",
      "     |\n",
      "     |      This method may be deprecated in a future release.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          message: The `AIMessage` to add.\n",
      "     |\n",
      "     |  add_messages(self, messages: 'Sequence[BaseMessage]') -> 'None'\n",
      "     |      Add a list of messages.\n",
      "     |\n",
      "     |      Implementations should over-ride this method to handle bulk addition of messages\n",
      "     |      in an efficient manner to avoid unnecessary round-trips to the underlying store.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          messages: A sequence of `BaseMessage` objects to store.\n",
      "     |\n",
      "     |  add_user_message(self, message: 'HumanMessage | str') -> 'None'\n",
      "     |      Convenience method for adding a human message string to the store.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          This is a convenience method. Code should favor the bulk `add_messages`\n",
      "     |          interface instead to save on round-trips to the persistence layer.\n",
      "     |\n",
      "     |      This method may be deprecated in a future release.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          message: The `HumanMessage` to add to the store.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseChatMessageHistory:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __copy__(self) -> 'Self'\n",
      "     |      Returns a shallow copy of the model.\n",
      "     |\n",
      "     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      "     |      Returns a deep copy of the model.\n",
      "     |\n",
      "     |  __delattr__(self, item: 'str') -> 'Any'\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __eq__(self, other: 'Any') -> 'bool'\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, item: 'str') -> 'Any'\n",
      "     |\n",
      "     |  __getstate__(self) -> 'dict[Any, Any]'\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __init__(self, /, **data: 'Any') -> 'None'\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |\n",
      "     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      "     |      validated to form a valid model.\n",
      "     |\n",
      "     |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      "     |\n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      So `dict(model)` works.\n",
      "     |\n",
      "     |  __pretty__(self, fmt: 'Callable[[Any], Any]', **kwargs: 'Any') -> 'Generator[Any]' from pydantic._internal._repr.Representation\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      "     |\n",
      "     |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      "     |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      "     |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      "     |\n",
      "     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |\n",
      "     |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |      Returns the string representation of a recursive object.\n",
      "     |\n",
      "     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      "     |\n",
      "     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      "     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      "     |\n",
      "     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      "     |\n",
      "     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! warning \"Deprecated\"\n",
      "     |          This method is now deprecated; use `model_copy` instead.\n",
      "     |\n",
      "     |      If you need `include` or `exclude`, use:\n",
      "     |\n",
      "     |      ```python {test=\"skip\" lint=\"skip\"}\n",
      "     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      "     |      data = {**data, **(update or {})}\n",
      "     |      copied = self.model_validate(data)\n",
      "     |      ```\n",
      "     |\n",
      "     |      Args:\n",
      "     |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      "     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      "     |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      "     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A copy of the model with included, excluded and updated fields as specified.\n",
      "     |\n",
      "     |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      "     |      !!! abstract \"Usage Documentation\"\n",
      "     |          [`model_copy`](../concepts/models.md#model-copy)\n",
      "     |\n",
      "     |      Returns a copy of the model.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          The underlying instance's [`__dict__`][object.__dict__] attribute is copied. This\n",
      "     |          might have unexpected side effects if you store anything in it, on top of the model\n",
      "     |          fields (e.g. the value of [cached properties][functools.cached_property]).\n",
      "     |\n",
      "     |      Args:\n",
      "     |          update: Values to change/add in the new model. Note: the data is not validated\n",
      "     |              before creating the new model. You should trust this data.\n",
      "     |          deep: Set to `True` to make a deep copy of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          New model instance.\n",
      "     |\n",
      "     |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      "     |      !!! abstract \"Usage Documentation\"\n",
      "     |          [`model_dump`](../concepts/serialization.md#python-mode)\n",
      "     |\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          mode: The mode in which `to_python` should run.\n",
      "     |              If mode is 'json', the output will only contain JSON serializable types.\n",
      "     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      "     |          include: A set of fields to include in the output.\n",
      "     |          exclude: A set of fields to exclude from the output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          exclude_computed_fields: Whether to exclude computed fields.\n",
      "     |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      "     |              `round_trip` parameter instead.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      "     |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the model.\n",
      "     |\n",
      "     |  model_dump_json(self, *, indent: 'int | None' = None, ensure_ascii: 'bool' = False, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'str'\n",
      "     |      !!! abstract \"Usage Documentation\"\n",
      "     |          [`model_dump_json`](../concepts/serialization.md#json-mode)\n",
      "     |\n",
      "     |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      "     |          ensure_ascii: If `True`, the output is guaranteed to have all incoming non-ASCII characters escaped.\n",
      "     |              If `False` (the default), these characters will be output as-is.\n",
      "     |          include: Field(s) to include in the JSON output.\n",
      "     |          exclude: Field(s) to exclude from the JSON output.\n",
      "     |          context: Additional context to pass to the serializer.\n",
      "     |          by_alias: Whether to serialize using field aliases.\n",
      "     |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      "     |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      "     |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      "     |          exclude_computed_fields: Whether to exclude computed fields.\n",
      "     |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      "     |              `round_trip` parameter instead.\n",
      "     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      "     |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      "     |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      "     |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      "     |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      "     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON string representation of the model.\n",
      "     |\n",
      "     |  model_post_init(self, context: 'Any', /) -> 'None'\n",
      "     |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      "     |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      "     |\n",
      "     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      "     |\n",
      "     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      "     |      Hook into generating the model's JSON schema.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          core_schema: A `pydantic-core` CoreSchema.\n",
      "     |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      "     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      "     |              or just call the handler with the original schema.\n",
      "     |          handler: Call into Pydantic's internal JSON schema generation.\n",
      "     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      "     |              generation fails.\n",
      "     |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      "     |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      "     |              for a type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A JSON schema, as a Python object.\n",
      "     |\n",
      "     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      "     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      "     |      only after basic class initialization is complete. In particular, attributes like `model_fields` will\n",
      "     |      be present when this is called, but forward annotations are not guaranteed to be resolved yet,\n",
      "     |      meaning that creating an instance of the class may fail.\n",
      "     |\n",
      "     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      "     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      "     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      "     |\n",
      "     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      "     |      any kwargs passed to the class definition that aren't used internally by Pydantic.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      "     |              by Pydantic.\n",
      "     |\n",
      "     |      Note:\n",
      "     |          You may want to override [`__pydantic_on_complete__()`][pydantic.main.BaseModel.__pydantic_on_complete__]\n",
      "     |          instead, which is called once the class and its fields are fully initialized and ready for validation.\n",
      "     |\n",
      "     |  __pydantic_on_complete__() -> 'None'\n",
      "     |      This is called once the class and its fields are fully initialized and ready to be used.\n",
      "     |\n",
      "     |      This typically happens when the class is created (just before\n",
      "     |      [`__pydantic_init_subclass__()`][pydantic.main.BaseModel.__pydantic_init_subclass__] is called on the superclass),\n",
      "     |      except when forward annotations are used that could not immediately be resolved.\n",
      "     |      In that case, it will be called later, when the model is rebuilt automatically or explicitly using\n",
      "     |      [`model_rebuild()`][pydantic.main.BaseModel.model_rebuild].\n",
      "     |\n",
      "     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  from_orm(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      "     |      Creates a new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |\n",
      "     |      !!! note\n",
      "     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      "     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      "     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      "     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      "     |          an error if extra values are passed, but they will be ignored.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      "     |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      "     |              Otherwise, the field names from the `values` argument will be used.\n",
      "     |          values: Trusted or pre-validated data dictionary.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A new instance of the `Model` class with validated data.\n",
      "     |\n",
      "     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation', *, union_format: \"Literal['any_of', 'primitive_type_array']\" = 'any_of') -> 'dict[str, Any]'\n",
      "     |      Generates a JSON schema for a model class.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          by_alias: Whether to use attribute aliases or not.\n",
      "     |          ref_template: The reference template.\n",
      "     |          union_format: The format to use when combining schemas from unions together. Can be one of:\n",
      "     |\n",
      "     |              - `'any_of'`: Use the [`anyOf`](https://json-schema.org/understanding-json-schema/reference/combining#anyOf)\n",
      "     |              keyword to combine schemas (the default).\n",
      "     |              - `'primitive_type_array'`: Use the [`type`](https://json-schema.org/understanding-json-schema/reference/type)\n",
      "     |              keyword as an array of strings, containing each type of the combination. If any of the schemas is not a primitive\n",
      "     |              type (`string`, `boolean`, `null`, `integer` or `number`) or contains constraints/metadata, falls back to\n",
      "     |              `any_of`.\n",
      "     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      "     |              `GenerateJsonSchema` with your desired modifications\n",
      "     |          mode: The mode in which to generate the schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The JSON schema for the given model class.\n",
      "     |\n",
      "     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      "     |      Compute the class name for parametrizations of generic classes.\n",
      "     |\n",
      "     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          params: Tuple of types of the class. Given a generic class\n",
      "     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      "     |              the value `(str, int)` would be passed to `params`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      "     |\n",
      "     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      "     |      Try to rebuild the pydantic-core schema for the model.\n",
      "     |\n",
      "     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      "     |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      "     |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      "     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      "     |          _types_namespace: The types namespace, defaults to `None`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      "     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      "     |\n",
      "     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self'\n",
      "     |      Validate a pydantic model instance.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      "     |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      "     |          from_attributes: Whether to extract data from object attributes.\n",
      "     |          context: Additional context to pass to the validator.\n",
      "     |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      "     |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If the object could not be validated.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated model instance.\n",
      "     |\n",
      "     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self'\n",
      "     |      !!! abstract \"Usage Documentation\"\n",
      "     |          [JSON Parsing](../concepts/json.md#json-parsing)\n",
      "     |\n",
      "     |      Validate the given JSON data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_data: The JSON data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      "     |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      "     |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      "     |\n",
      "     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self'\n",
      "     |      Validate the given object with string data against the Pydantic model.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          obj: The object containing string data to validate.\n",
      "     |          strict: Whether to enforce types strictly.\n",
      "     |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      "     |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      "     |          context: Extra variables to pass to the validator.\n",
      "     |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      "     |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          The validated Pydantic model.\n",
      "     |\n",
      "     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  parse_obj(obj: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      "     |\n",
      "     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      "     |\n",
      "     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      "     |\n",
      "     |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      "     |\n",
      "     |  validate(value: 'Any') -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __fields_set__\n",
      "     |\n",
      "     |  model_extra\n",
      "     |      Get extra fields set during validation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      "     |\n",
      "     |  model_fields_set\n",
      "     |      Returns the set of fields that have been explicitly set on this model instance.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A set of strings representing the fields that have been set,\n",
      "     |              i.e. that were not filled from defaults.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __pydantic_extra__\n",
      "     |\n",
      "     |  __pydantic_fields_set__\n",
      "     |\n",
      "     |  __pydantic_private__\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  __pydantic_root_model__ = False\n",
      "     |\n",
      "     |  model_computed_fields = {}\n",
      "     |\n",
      "     |  model_fields = {'messages': FieldInfo(annotation=list[BaseMessage], re...\n",
      "\n",
      "DATA\n",
      "    TYPE_CHECKING = False\n",
      "\n",
      "FILE\n",
      "    c:\\developer\\rag_krishai_bootcamp\\data_ingestion\\.venv\\lib\\site-packages\\langchain_core\\chat_history.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(langchain_core.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61369520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package langchain:\n",
      "\n",
      "NAME\n",
      "    langchain - Main entrypoint into LangChain.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    agents (package)\n",
      "    chat_models (package)\n",
      "    embeddings (package)\n",
      "    messages (package)\n",
      "    rate_limiters (package)\n",
      "    tools (package)\n",
      "\n",
      "VERSION\n",
      "    1.0.4\n",
      "\n",
      "FILE\n",
      "    c:\\developer\\rag_krishai_bootcamp\\data_ingestion\\.venv\\lib\\site-packages\\langchain\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(langchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7efce",
   "metadata": {},
   "source": [
    "#### Using GROQ LLM's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766dace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8779d925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning (ML) is a subfield of artificial intelligence (AI) that focuses on enabling computers to learn from data without being explicitly programmed. \\n\\nHere\\'s a breakdown:\\n\\n**How it works:**\\n\\n* **Data is the fuel:** ML algorithms are trained on large datasets, allowing them to identify patterns and relationships within the data.\\n* **Algorithms do the learning:** These algorithms use mathematical models to analyze the data and make predictions or decisions based on what they learn. \\n* **The more data, the better:** The quality and quantity of data directly impact the accuracy and performance of ML models.\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised learning:**  Algorithms are trained on labeled datasets (e.g., images with labels like \"cat\" or \"dog\"). They learn to predict outcomes based on this labeled information.\\n* **Unsupervised learning:** Algorithms analyze unlabeled data and try to find hidden patterns, structures, or relationships within it (e.g., grouping customers based on purchasing behavior).\\n* **Reinforcement learning:**  Algorithms learn by interacting with an environment and receiving rewards or penalties for their actions (e.g., training a robot to navigate a maze).\\n\\n**Real-world applications:**\\n\\nMachine learning is used in countless areas, including:\\n\\n* **Image recognition:** Identifying objects, faces, and patterns in images.\\n* **Natural language processing:** Understanding and generating human language.\\n* **Predictive analytics:** Forecasting future trends based on historical data.\\n* **Recommendation systems:** Suggesting products or content to users based on their preferences.\\n* **Fraud detection:** Identifying suspicious transactions or activities.\\n* **Medical diagnosis:** Assisting doctors in diagnosing diseases based on patient data.\\n\\n**Benefits of Machine Learning:**\\n\\n* **Automation:** Automating tasks and processes that would otherwise require human intervention.\\n* **Improved accuracy:** ML algorithms can often outperform humans in specific tasks, especially when dealing with large datasets.\\n* **Personalization:** Delivering customized experiences for users based on their individual preferences.\\n* **Innovation:** Enabling new discoveries and solutions across various industries.\\n\\n\\n**In short:** Machine learning is a powerful tool that allows computers to learn from data and make predictions or decisions without explicit programming, leading to significant advancements in various fields. \\n', additional_kwargs={}, response_metadata={'model': 'gemma2:2b', 'created_at': '2025-11-18T13:48:49.4219971Z', 'done': True, 'done_reason': 'stop', 'total_duration': 37618674400, 'load_duration': 23984851000, 'prompt_eval_count': 14, 'prompt_eval_duration': 684000000, 'eval_count': 473, 'eval_duration': 12939000000, 'model_name': 'gemma2:2b', 'model_provider': 'ollama'}, id='lc_run--dfda7d0a-0914-4cf5-91b7-57a8f5cffff4-0', usage_metadata={'input_tokens': 14, 'output_tokens': 473, 'total_tokens': 487})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_llm = ChatOllama(model=\"gemma2:2b\", temperature=0)\n",
    "ollama_llm.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10613517",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A 2-b billion model took nearly ~ 40 seconds to respond in my local computer with 6 GB VRAM, 16GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea8899fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c9f3b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9f4ac5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b7512f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence (AI) that involves the use of algorithms and statistical models to enable machines to learn from data, make decisions, and improve their performance over time. The primary goal of machine learning is to enable machines to automatically improve their performance on a task without being explicitly programmed.\\n\\nMachine learning involves training a model on a dataset, which allows the model to learn patterns and relationships within the data. The model can then use this knowledge to make predictions, classify new data, or make decisions.\\n\\nThere are several key characteristics of machine learning:\\n\\n1. **Learning from data**: Machine learning models learn from data, rather than being explicitly programmed.\\n2. **Improvement over time**: Machine learning models can improve their performance over time as they receive more data and experience.\\n3. **Autonomy**: Machine learning models can make decisions and take actions without human intervention.\\n4. **Flexibility**: Machine learning models can be applied to a wide range of tasks, including classification, regression, clustering, and more.\\n\\nMachine learning has many applications, including:\\n\\n1. **Image and speech recognition**: Machine learning is used in applications such as facial recognition, object detection, and speech-to-text systems.\\n2. **Natural language processing**: Machine learning is used in applications such as language translation, sentiment analysis, and text summarization.\\n3. **Predictive maintenance**: Machine learning is used in applications such as predictive maintenance, where machines can predict when maintenance is required.\\n4. **Recommendation systems**: Machine learning is used in applications such as recommendation systems, where machines can suggest products or services based on user behavior.\\n\\nThere are several types of machine learning, including:\\n\\n1. **Supervised learning**: The model is trained on labeled data, where the correct output is already known.\\n2. **Unsupervised learning**: The model is trained on unlabeled data, where the correct output is not known.\\n3. **Reinforcement learning**: The model learns through trial and error, receiving rewards or penalties for its actions.\\n4. **Deep learning**: A type of machine learning that uses neural networks with multiple layers to learn complex patterns in data.\\n\\nSome of the key benefits of machine learning include:\\n\\n1. **Improved accuracy**: Machine learning models can make more accurate predictions and decisions than traditional methods.\\n2. **Increased efficiency**: Machine learning models can automate tasks and improve efficiency.\\n3. **Scalability**: Machine learning models can be applied to large datasets and complex problems.\\n4. **Flexibility**: Machine learning models can be applied to a wide range of tasks and domains.\\n\\nHowever, machine learning also has some challenges and limitations, including:\\n\\n1. **Data quality**: Machine learning models require high-quality data to learn from.\\n2. **Overfitting**: Machine learning models can overfit the training data and fail to generalize to new data.\\n3. **Bias**: Machine learning models can perpetuate biases and prejudices present in the training data.\\n4. **Explainability**: Machine learning models can be difficult to interpret and understand.\\n\\nOverall, machine learning is a powerful tool that has many applications and benefits, but it also requires careful consideration of its challenges and limitations.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 638, 'prompt_tokens': 40, 'total_tokens': 678, 'completion_time': 0.696840104, 'prompt_time': 0.001794836, 'queue_time': 0.062044024, 'total_time': 0.69863494}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e750f72ec9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--93d6c912-75d8-4c6f-a6d1-e4037415b97c-0', usage_metadata={'input_tokens': 40, 'output_tokens': 638, 'total_tokens': 678})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm= ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "llm.invoke(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "892fb56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Machine Learning (ML)** is a branch of artificial intelligence that enables computers to learn patterns and make decisions from data, without being explicitly programmed for each specific task.\\n\\n### Core Idea\\n- **Learning from data**: Instead of hardcoding rules, an ML system is fed examples (inputoutput pairs or raw observations) and it automatically discovers the underlying relationships.\\n- **Generalization**: After training, the model can apply what it has learned to new, unseen data.\\n\\n### How It Works (Simplified)\\n1. **Collect Data**  Gather a representative set of examples.\\n2. **Choose a Model**  Pick an algorithm (e.g., linear regression, decision tree, neural network).\\n3. **Train**  Feed the data to the model so it adjusts internal parameters to minimize error.\\n4. **Validate**  Test on separate data to ensure it generalizes.\\n5. **Deploy**  Use the trained model to make predictions or decisions in realworld scenarios.\\n\\n### Types of Machine Learning\\n| Type | What It Does | Typical UseCases |\\n|------|--------------|-------------------|\\n| **Supervised** | Learns a mapping from inputs to known outputs. | Image classification, spam detection, regression tasks. |\\n| **Unsupervised** | Finds hidden structure in unlabeled data. | Clustering customers, anomaly detection, dimensionality reduction. |\\n| **Semisupervised** | Combines a small amount of labeled data with a large amount of unlabeled data. | Speech recognition, medical imaging. |\\n| **Reinforcement** | Learns by interacting with an environment and receiving rewards. | Game playing, robotics, recommendation systems. |\\n\\n### Key Concepts\\n- **Features**: Attributes or variables extracted from raw data.\\n- **Labels**: The target values we want the model to predict (in supervised learning).\\n- **Loss Function**: Quantifies how far the models predictions are from the true values; the training process minimizes this loss.\\n- **Overfitting / Underfitting**: Balancing model complexity to perform well on unseen data.\\n- **Evaluation Metrics**: Accuracy, precision, recall, F1score, ROCAUC, etc., depending on the task.\\n\\n### Common Algorithms\\n- **Linear Models**: Linear regression, logistic regression.\\n- **TreeBased**: Decision trees, random forests, gradientboosted trees (XGBoost, LightGBM).\\n- **Kernel Methods**: Support Vector Machines (SVM).\\n- **Neural Networks**: Feedforward nets, convolutional nets (CNNs), recurrent nets (RNNs), transformers.\\n- **Clustering**: Kmeans, DBSCAN, hierarchical clustering.\\n\\n### Practical Workflow\\n1. **Problem Definition**  Clarify the goal (e.g., predict house prices).\\n2. **Data Acquisition & Cleaning**  Handle missing values, outliers, and inconsistencies.\\n3. **Feature Engineering**  Create meaningful inputs (e.g., onehot encode categories, normalize scales).\\n4. **Model Selection & Hyperparameter Tuning**  Try different algorithms and tune settings (grid search, Bayesian optimization).\\n5. **Training & Validation**  Split data (train/validation/test) and monitor performance.\\n6. **Deployment & Monitoring**  Integrate into production, track drift, and retrain as needed.\\n\\n### Why It Matters\\n- **Automation**: ML can handle tasks that are too complex or timeconsuming for humans.\\n- **Insight**: It can uncover patterns and relationships hidden in large datasets.\\n- **Adaptability**: Models can improve over time as more data becomes available.\\n\\n---\\n\\n**Bottom line:** Machine Learning is the science of building systems that learn from data, adapt to new information, and perform tasks that would otherwise require explicit programming.', additional_kwargs={'reasoning_content': 'We need to answer: \"What is Machine Learning?\" Provide a concise explanation. Probably mention definition, supervised/unsupervised, algorithms, data, training, etc. Provide examples. Should be clear.'}, response_metadata={'token_usage': {'completion_tokens': 833, 'prompt_tokens': 76, 'total_tokens': 909, 'completion_time': 0.860674259, 'prompt_time': 0.004234463, 'queue_time': 0.052164647, 'total_time': 0.864908722, 'completion_tokens_details': {'reasoning_tokens': 42}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--d25c1138-41f3-4c14-8e04-e8c8192bcb19-0', usage_metadata={'input_tokens': 76, 'output_tokens': 833, 'total_tokens': 909})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm= ChatGroq(model=\"openai/gpt-oss-20b\", temperature=0)\n",
    "llm.invoke(\"What is Machine Learning?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Ingestion (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
