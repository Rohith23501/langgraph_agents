{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a5b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries \n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#langchain_core imports \n",
    "from langchain_core.documents import Document \n",
    "from langchain_core.runnables import RunnableAssign, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Langchain specific imports\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0610ac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a11f60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'AI Introduction', 'page': 1, 'topic': 'AI'}, page_content='\\n        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\\n        These systems are designed to think like humans and mimic their actions.\\n        AI can be categorized into narrow AI and general AI.\\n        '), Document(metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='\\n        Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.\\n        '), Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'DL'}, page_content='\\n        Deep Learning is a subset of machine learning based on artificial neural networks.\\n        It uses multiple layers to progressively extract higher-level features from raw input.\\n        Deep learning has revolutionized computer vision, NLP, and speech recognition.\\n        '), Document(metadata={'source': 'NLP Overview', 'page': 1, 'topic': 'NLP'}, page_content='\\n        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\\n        It combines computational linguistics with machine learning and deep learning models.\\n        Applications include chatbots, translation, sentiment analysis, and text summarization.\\n        ')]\n"
     ]
    }
   ],
   "source": [
    "sample_documents = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
    "        These systems are designed to think like humans and mimic their actions.\n",
    "        AI can be categorized into narrow AI and general AI.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"AI Introduction\", \"page\": 1, \"topic\": \"AI\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Machine Learning is a subset of AI that enables systems to learn from data.\n",
    "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
    "        Common types include supervised, unsupervised, and reinforcement learning.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"ML Basics\", \"page\": 1, \"topic\": \"ML\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Deep Learning is a subset of machine learning based on artificial neural networks.\n",
    "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
    "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"Deep Learning\", \"page\": 1, \"topic\": \"DL\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
    "        It combines computational linguistics with machine learning and deep learning models.\n",
    "        Applications include chatbots, translation, sentiment analysis, and text summarization.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"NLP Overview\", \"page\": 1, \"topic\": \"NLP\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(sample_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918ebe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "### text splitter \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators = [\" \"]\n",
    ")\n",
    "\n",
    "##split the documents into chunks \n",
    "chunks = text_splitter.split_documents(sample_documents)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bee0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the embedding models \n",
    "embeddings = OpenAIEmbeddings(\n",
    "model=\"text-embedding-3-small\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c1a39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = embeddings.embed_query(\"my shoes are black\")\n",
    "print(len(sample_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1382a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have embeddings for 3 of dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = embeddings.embed_documents([\"The sky is blue\", \"I love the blue sky\", \"The moon looks good today\"])\n",
    "\n",
    "print(f\"we have embeddings for {len(word_embeddings)} of dimension: {len(word_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f1986",
   "metadata": {},
   "source": [
    "#### Create FAISS Vector Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "437abebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 4 vectors\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=chunks\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89c3c08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector saved to 'faiss_index' directory\n"
     ]
    }
   ],
   "source": [
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "print(\"Vector saved to 'faiss_index' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59adf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load_vectorstore\n",
    "\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2833c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Deep Learning?\"\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6452c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning is a subset of machine learning based on artificial neural networks.\n",
      "        It uses multiple layers to progressively extract higher-level features from raw input.\n",
      "        Deep learning has revolutionized computer vision, NLP, and speech recognition.\n",
      "\n",
      "\n",
      "Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
      "        Common types include supervised, unsupervised, and reinforcement learning.\n",
      "\n",
      "\n",
      "Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
      "        It combines computational linguistics with machine learning and deep learning models.\n",
      "        Applications include chatbots, translation, sentiment analysis, and text summarization.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d4fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='e83bd58b-1235-4718-8ec8-b4b2c077a31c', metadata={'source': 'ML Basics', 'page': 1, 'topic': 'ML'}, page_content='Machine Learning is a subset of AI that enables systems to learn from data.\\n        Instead of being explicitly programmed, ML algorithms find patterns in data.\\n        Common types include supervised, unsupervised, and reinforcement learning.'), np.float32(1.0857663))]\n"
     ]
    }
   ],
   "source": [
    "filter_dict = {\"topic\":\"ML\"}\n",
    "\n",
    "filtered_results = vectorstore.similarity_search_with_score(\n",
    "    query,\n",
    "    k=3, \n",
    "    filter=filter_dict\n",
    ")\n",
    "\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1852f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the document:  1.0858\n",
      "\n",
      " With Content: Machine Learning is a subset of AI that enables systems to learn from data.\n",
      "        Instead of being explicitly programmed, ML algorithms find patterns in data.\n",
      "        Common types include supervised, unsupervised, and reinforcement learning.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc, score in filtered_results:\n",
    "    print(f\"Score for the document: {score: .4f}\")\n",
    "    print(f\"\\n With Content: {doc.page_content}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f746f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b295844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0a553",
   "metadata": {},
   "source": [
    "#### Build RAG chain with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af811d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be008211",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm = ChatGroq(model=\"groq/compound-mini\", \n",
    "                    temperature=0.5,\n",
    "                    max_retries=2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe713a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes—you’re connected and we can chat right now. How can I help you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 447, 'total_tokens': 550, 'completion_time': 0.231641, 'prompt_time': 0.02102, 'queue_time': 0.109492, 'total_time': 0.252662}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--0e7ebf72-07a6-4a1d-9811-05b4596c69ea-0', usage_metadata={'input_tokens': 447, 'output_tokens': 103, 'total_tokens': 550})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm.invoke(\"did i connect to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f627b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For qroq api free tier \n",
    "## groq/compound currently has 250 requests per day with no tokens per day limit\n",
    "##  llama-3.1-8b-instant has 14.4k requests per day wiht a 500k token limit\n",
    "##  also metalama/llama-4-maverick|scout-17b-128e|1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eb767d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\" Answer the question based on the following context:\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44fdc639",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\",\n",
    "                        search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95023c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E2D7BBDA60>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3319e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs: List[Document]) -> str:\n",
    "    \"\"\" Combines all the docs to make the \n",
    "    relevant context to be send through RAG chain\"\"\"\n",
    "    all_content = []\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get(\"source\", \"unknown\")\n",
    "        all_content.append(f\"(Source: {source}):\\n{doc.page_content}\")\n",
    "\n",
    "    return \"\\n\\n\".join(all_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc27b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8924838",
   "metadata": {},
   "outputs": [],
   "source": [
    "now_rag_chain = RunnableParallel(\n",
    "    context = retriever | RunnableLambda(combine_docs),\n",
    "    question= RunnablePassthrough()\n",
    ") | simple_prompt | groq_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba499802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Autoencoders\\u202f—\\u202fa quick overview**\\n\\nAn **autoencoder** is a type of artificial neural network used in deep learning for **unsupervised representation learning**. Its goal is to learn a compact (latent) representation of the input data and then reconstruct the original input from that representation.  \\n\\n---\\n\\n### 1. Core architecture  \\n\\n| Component | What it does |\\n|-----------|--------------|\\n| **Encoder** | Takes the raw input \\\\(x\\\\) and maps it to a lower‑dimensional latent vector \\\\(z = f_{\\\\text{enc}}(x)\\\\). This “bottleneck” forces the network to capture the most salient features. |\\n| **Latent space (bottleneck)** | The compressed code that ideally contains the essential information about the input while discarding redundancy and noise. |\\n| **Decoder** | Reconstructs the input from the latent code \\\\( \\\\hat{x} = f_{\\\\text{dec}}(z) \\\\). |\\n\\nDuring training the network minimizes a **reconstruction loss** (e.g., mean‑squared error for images, binary cross‑entropy for binary data) that measures how close \\\\(\\\\hat{x}\\\\) is to the original \\\\(x\\\\).\\n\\n---\\n\\n### 2. Why they matter  \\n\\n- **Dimensionality reduction** – similar to PCA but can capture non‑linear relationships.  \\n- **Feature learning** – the latent vectors can be used as inputs to downstream supervised models.  \\n- **Data denoising** – by training to reconstruct clean data from noisy inputs (denoising autoencoders).  \\n- **Anomaly detection** – unusual samples yield higher reconstruction error.  \\n- **Data compression** – the encoder can serve as a learned compressor; the decoder acts as a decompressor.  \\n- **Generative modeling** – variants such as Variational Autoencoders (VAEs) can sample new data from the learned latent distribution.\\n\\n---\\n\\n### 3. Common variants  \\n\\n| Variant | Key idea / use case |\\n|--------|---------------------|\\n| **Vanilla (fully‑connected) autoencoder** | Simple dense layers; good for low‑dimensional tabular data. |\\n| **Convolutional autoencoder (CAE)** | Uses Conv/Deconv layers; excels with images and spatial data. |\\n| **Denoising autoencoder** | Trains on corrupted inputs, learns to recover the clean version. |\\n| **Sparse autoencoder** | Adds a sparsity penalty on the latent activations, encouraging a “few‑active‑neurons” representation. |\\n| **Contractive autoencoder** | Penalizes the Jacobian of the encoder to make the representation robust to small input changes. |\\n| **Variational autoencoder (VAE)** | Treats the latent space probabilistically (learns mean\\u202f&\\u202fvariance); enables sampling and generative tasks. |\\n| **Sequence autoencoder** | Uses recurrent or transformer blocks for time‑series or text data. |\\n\\n---\\n\\n### 4. How to train an autoencoder  \\n\\n1. **Prepare data** – usually normalized (e.g., pixel values in \\\\([0,1]\\\\)).  \\n2. **Define the network** – choose encoder/decoder depth, size of bottleneck, and any convolutional layers if dealing with images.  \\n3. **Choose a loss** – MSE for continuous data, binary cross‑entropy for binary images, or a custom loss for specific tasks.  \\n4. **Optimize** – standard gradient‑descent optimizers (Adam, RMSprop) work well.  \\n5. **Validate** – monitor reconstruction loss on a held‑out set; optionally inspect reconstructed samples.  \\n\\n---\\n\\n### 5. Example (tiny image autoencoder in PyTorch)\\n\\n```python\\nimport torch, torch.nn as nn\\n\\nclass SimpleAE(nn.Module):\\n    def __init__(self, latent_dim=64):\\n        super().__init__()\\n        # Encoder\\n        self.enc = nn.Sequential(\\n            nn.Flatten(),\\n            nn.Linear(28*28, 256),\\n            nn.ReLU(),\\n            nn.Linear(256, latent_dim)   # bottleneck\\n        )\\n        # Decoder\\n        self.dec = nn.Sequential(\\n            nn.Linear(latent_dim, 256),\\n            nn.ReLU(),\\n            nn.Linear(256, 28*28),\\n            nn.Sigmoid(),                # output in [0,1]\\n            nn.Unflatten(1, (1,28,28))\\n        )\\n\\n    def forward(self, x):\\n        z = self.enc(x)\\n        return self.dec(z)\\n\\n# training loop (omitted for brevity) …\\n```\\n\\nAfter training, `model.enc(x)` yields a compact 64‑dimensional representation that can be used for clustering, classification, or as a compressed storage format.\\n\\n---\\n\\n### 6. When to use an autoencoder  \\n\\n- **You have unlabeled data** and want to extract useful features without manual labeling.  \\n- **You need to compress high‑dimensional data** (images, audio, sensor streams) while preserving most of the information.  \\n- **You want to clean noisy data** (e.g., remove sensor noise, restore corrupted images).  \\n- **You need a baseline anomaly detector** (high reconstruction error → potential outlier).  \\n- **You are building a generative model** and need a latent space that can be sampled from (VAE, VQ‑VAE, etc.).\\n\\n---\\n\\n### TL;DR  \\n\\nAn autoencoder is a neural network that learns to compress data into a low‑dimensional latent code (encoder) and then reconstruct the original data (decoder). By training to minimize reconstruction error, it discovers useful, often non‑linear, representations of the data. Variants such as convolutional, denoising, sparse, contractive, and variational autoencoders extend the basic idea for images, robustness, sparsity, and generative modeling. They are widely used for dimensionality reduction, feature learning, denoising, anomaly detection, compression, and as building blocks for more advanced deep‑learning systems.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_rag_chain.invoke(\"can you explain me about auto encoders in deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64131e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Ingestion (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
